## Removing noisy genes

[START EXPANDIBLE]: #
`r EXPAND_bx` 
Expand to know <b>why noisy genes must be removed</b></summary>

**Noisy genes**  (those having very low counts across all the libraries) should be removed prior to downstream analysis due to biological and statistical reasons [@Chen2016aa]. From **biological point of view**, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be considered biologically important. **Statistically**, genes with consistently low counts are very unlikely be assessed as significantly differentially expressed because low counts do not provide enough statistical evidence for a reliable judgement to be made.
The minimum requirement is the removal of unexpressed genes (those with `counts == 0` in all samples or conditions, that is all columns).

The amount of genes that are not expressed in your samples, expressed in all samples and expressed in some samples is then calculated.

```{r filter1, results='hold'}
# Looking for genes expressed in ALL samples (TRUE)
none_is0 <- table(rowSums(x$counts == 0) == 0)
none_is0 <- Avoid_0_counts(none_is0)           # To have TRUE and FALSE values


# Counting genes NOT EXPRESSED in any sample (TRUE)
COL_NUMBER <- length(COL_NAMES)
all_are0 <- table(rowSums(x$counts == 0) == COL_NUMBER)
all_are0 <- Avoid_0_counts(all_are0)           # To have TRUE and FALSE values


# Expressed in SOME samples
total_genes <- dim(x)[1] # or nrow(x$counts)
at_least_1 <- total_genes - none_is0[["TRUE"]] - all_are0[["TRUE"]]
```

But as a rule of thumb, only genes having a count of at least 10â€“15 in at least one set of replicates (variable `MIN_REPL` calculated below from `EXP_FACTORS`) should be retained [@Chen2016aa].
Since it was recently demonstrated that the removal of genes mapping less than 30-reads make sure that further fold changes were not skewed by small read counts, with a dramatic decrease of the maximum FC detected [@Thawng2022aa], the minimal number of counts `MIN_COUNTS` was parametrised. We will take advantage of the `filterByExpr()` function that keeps genes that have at least `min.count` reads in a worthwhile number samples (calculated from the dessing matrix if provided or set in the `large.n` parameter).

</details> 
[END EXPANDIBLE]: #


`r NOTE_bx` 
The filtering cannot rely on `counts` when library sizes are very different. Hence, [CPM] (_counts per million_) should be used instead of counts. This is why the value of the `min.count` argument in `filterByExpr()` is  converted into cpm before using it as a threshold.
</div>

To avoid favouring genes that are expressed in larger libraries over those expressed in smaller libraries, an additional removal of genes based on [CPM] was incorporated [@Law2016yj,@Chen2016aa] based on the threshold `MIN_CPM` defined by the user in `configure_wf.R`. Hence, only genes with `cpm > MIN_CPM` in at least one set of replicates (`MIN_REPL`) will be retained.

The minimal number of samples with `cpm > MIN_CPM` is the lowest number of replicates as defined in `EXP_FACTORS`. This ensures that a gene will be retained if it is expressed in all libraries belonging to at least one of the experimental conditions.

```{r numRepFilt}
# calculate the minimal number of samples that must have cpm or counts > 0
MIN_REPL <- min(table(EXP_FACTORS))

# non stringent filtering
MIN_COUNTS <- 10                          # default value in filterByExpr
keep.exprs <- filterByExpr(x, min.count = MIN_COUNTS, 
                           min.total.count = 1.5*MIN_COUNTS,  # due that it is 15 when MIN_COUNTS is 10
                           large.n = MIN_REPL)
filt_tmp <- table(keep.exprs)             # see in TRUE how many genes pass the filter
filt_tmp <- Avoid_0_counts(filt_tmp)      # To have TRUE and FALSE values
x.filt_tmp <- x[keep.exprs, , keep.lib.sizes = FALSE]

# CMP for the filtered object containing raw data
x.cpm <- cpm(x.filt_tmp)

# filtering by CPM
keep.exprs <- rowSums(x.cpm > MIN_CPM) >= MIN_REPL
filteredOK <- table(keep.exprs) # see in TRUE how many genes pass the filter
filteredOK <- Avoid_0_counts(filteredOK)

x.filt <- x.filt_tmp[keep.exprs, , keep.lib.sizes = FALSE]  # keep.lib.sizes=FALSE causes the library sizes to be recomputed after the filtering
```

The **final balance** is the following:

Genes | Amount  | Percent (%)
:---- | ----:   | ---:
Total                                   | `r total_genes`         | 100
Expressed in all samples                | `r none_is0[["TRUE"]]`  | `r round(100 * none_is0[["TRUE"]]/total_genes)`
Not expressed in at least 1 sample      | `r at_least_1`          | `r round(100 * at_least_1/total_genes)`
Never expressed                         | `r all_are0[["TRUE"]]`  | `r round(100 * all_are0[["TRUE"]]/total_genes)`
Tentatively useful                      | `r all_are0[["FALSE"]]` | `r round(100 * all_are0[["FALSE"]]/total_genes)`
Useful after `filterByExpr()`           | `r filt_tmp[["TRUE"]]`  | `r round(100 * filt_tmp[["TRUE"]]/total_genes)`
Really useful after `CMP >` `r MIN_CPM` | `r filteredOK[["TRUE"]]`| `r round(100 * filteredOK[["TRUE"]]/total_genes)`



## Data without noise {.tabset .tabset-fade .tabset-pills}

### Density plots {-}

[START EXPANDIBLE]: #
`r EXPAND_bx` 
Expand to read about the <b>density plot</b></summary>

The density of logCPM (`lcpm`) values will be plotted for each sample, where

* _dotted_ vertical line at `CPM = 0` (equivalent to `logCPM = 1`) will pinpoint the minimum logCPM threshold;
* _dashed_ vertical line will mark the main zone of gene removal. 

These reference lines are calculated as follows:

```{r cutoffs}
# To define the same range of density for all data
Y_REDUCTION <- 1e-6
L <- mean(x$samples$lib.size) * Y_REDUCTION
M <- median(x$samples$lib.size) * Y_REDUCTION
# a cutoff line to sepparate useful from useless genes
genes.cutoff <- log2(10/M + 2/L)
# remove needless variables
rm(L, M, Y_REDUCTION)
```

**Why using logCPM?** Because genes have very different variances, and the variance is monotonically growing with the mean, making genes with higher expression tending to have higher variance. Hence, it might be difficult to capture the expression variation due to the biological condition since it is _masked_ by this natural tendency. Transforming counts into logCPMs instead of [CPM]s make the genes easily comparable as they are brought onto a common scale with a Gaussian distribution. Note that log-transformed data yield explained variances roughly similar to the standardised data (when each variable is centered and scaled to have unit variance). However, for further differential expression, counts should not be log-transformed or normalised by TPM, as [described in detail by Lior Pachter in 2017](https://liorpachter.wordpress.com/2017/08/02/how-not-to-perform-a-differential-expression-analysis-or-science/).

</details> 
[END EXPANDIBLE]: #


Density plots are produced using `RColorBrewer` within local function `PlotGeneDensity()` to individualise samples.

```{r densityplots, fig.width=4, fig.height=5, out.width=c('50%', '50%'), fig.show='hold'}
# calculation of CPM and logCPM
# for raw data (x.cpm was already calculated)
x.lcpm <- cpm(x, log = TRUE)
# for filtered data
x.filt.lcpm <- cpm(x.filt, log = TRUE)
x.filt.cpm <- cpm(x.filt)

# density plots of raw data and filtered data
PlotGeneDensity(x.lcpm, genes.cutoff, "Raw data")
PlotGeneDensity(x.filt.lcpm, genes.cutoff, "After filtering")

# remove needless variables
rm(none_is0, all_are0, filteredOK, keep.exprs, filt_tmp) # from previous chunk
rm(genes.cutoff, x.lcpm, x.filt.lcpm, x.filt_tmp)
```

`r NOTE_bx`
After filtering, density lines should be nearly identical following a gauss-shaped profile. Peak at very low logCPM should disappear.
</div>

***

### Inspect filtered data {#filterdSizeMDSPCA}

Let`s see the new library sizes and sample grouping in [MDS] and [PCA] plots to compare with previous results with [raw data](#origSizeMDS).


```{r sizesMDSplotsFiltered, fig.width=6, fig.height=5, out.width=c('33%', '33%', '33%'), fig.show='hold'}
# Reconstruct libsizes after filtering.
# These new, effective library sizes will be used  in all downsteam analyses
x.filt$samples$lib.size <- colSums(x.filt$counts)

# create a place at rigth (8) for the legend outside the graph
# structure of mar = c(bottom, left, top, right)
par(mar = c(4, 3, 3, 8), xpd = TRUE) 

barplot(x.filt$samples$lib.size * 1e-6, 
        names = COL_NAMES, 
        col = EXP_COLORS,
        ylab = "Library size (millions)", 
        las = 2, 
        main = "Library sizes after filtering") 

# legend to indicate the correspondence of colours and factors in all plots
legend("topright", inset = c(-0.3, 0), # legend outside the plot 
       legend = as.vector(UNIQ_FACTORS), 
       fill = unique(EXP_COLORS),
       cex = 0.8)

# return to mar default values
par(mar = c(5, 4, 4, 2), xpd = TRUE)

plotMDS(x.filt, 
        col = EXP_COLORS, 
        main = "MDS relative similarities after filtering")

pca_sum <- PlotMyPCA(x.filt$counts, "PCA of filtered data")
```

> **IMPORTANT:** Library sizes appear to be the same than in [previous plot](#origSizeMDS) since only genes with very few counts were removed.

`r NOTE_bx` Samples should group similar to [previous MDS and PCA plots](#origSizeMDS) or **even better**, since filtering must remove noisy data and improve sample clustering.</div>

`r WARN_bx` If inferior sample grouping, you have a problem with your samples. Take results with caution.</div>





## Save filtered counts 

Gene counts after filtering are saved in a **.tsv** (_tab separated values_) file where gene codes are in rows and experimental data in columns.

```{r datatablefiltered}
# SaveTSV() is difined in functions_wr.R
fileName <- SaveTSV(x.filt$counts, "filteredData-")
message(fileName, "\n", "contains filtered gene counts")
```
